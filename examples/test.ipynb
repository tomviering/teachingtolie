{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "from torchvision import models\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vgg = models.vgg19(pretrained=True)\n",
    "my_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Conv2d\n",
    "\n",
    "w = list(my_vgg.features[34].parameters())\n",
    "print(w[0].shape) # filters\n",
    "print(w[1].shape) # biases\n",
    "#print(w[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 3.0775, 7.6843, 2.5410, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gradcam import preprocess_image \n",
    "\n",
    "image_path = 'examples/both.png'\n",
    "\n",
    "img = cv2.imread(image_path, 1)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "input = preprocess_image(img)\n",
    "\n",
    "out = my_vgg.features(input)\n",
    "out.shape\n",
    "\n",
    "out[0,511,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I used this code to find out what the indices are of the last featuremap.\n",
    "# apparently, when the featuremap is reshaped, the last featuremap are the last 49 elements of the reshaped vector\n",
    "myfeat = torch.Tensor(out)\n",
    "myfeat[0,:,:,:] = 0\n",
    "myfeat[0,511,:,:] = 1\n",
    "myfeat\n",
    "\n",
    "x = myfeat.view(myfeat.size(0), -1)\n",
    "x[0,0] = 5\n",
    "x[0,25088-7*7-2:] #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 24])\n",
      "torch.Size([4096, 24])\n",
      "0\n",
      "tensor(-1., requires_grad=True)\n",
      "1\n",
      "tensor(-1., requires_grad=True)\n",
      "2\n",
      "tensor(-1., requires_grad=True)\n",
      "3\n",
      "tensor(-1., requires_grad=True)\n",
      "4\n",
      "tensor(-1., requires_grad=True)\n",
      "5\n",
      "tensor(-1., requires_grad=True)\n",
      "6\n",
      "tensor(-1., requires_grad=True)\n",
      "7\n",
      "tensor(-1., requires_grad=True)\n",
      "8\n",
      "tensor(-1., requires_grad=True)\n",
      "9\n",
      "tensor(-1., requires_grad=True)\n",
      "10\n",
      "tensor(-1., requires_grad=True)\n",
      "11\n",
      "tensor(-1., requires_grad=True)\n",
      "12\n",
      "tensor(-1., requires_grad=True)\n",
      "13\n",
      "tensor(-1., requires_grad=True)\n",
      "14\n",
      "tensor(-1., requires_grad=True)\n",
      "15\n",
      "tensor(-1., requires_grad=True)\n",
      "16\n",
      "tensor(-1., requires_grad=True)\n",
      "17\n",
      "tensor(-1., requires_grad=True)\n",
      "18\n",
      "tensor(-1., requires_grad=True)\n",
      "19\n",
      "tensor(-1., requires_grad=True)\n",
      "20\n",
      "tensor(-1., requires_grad=True)\n",
      "21\n",
      "tensor(-1., requires_grad=True)\n",
      "22\n",
      "tensor(-1., requires_grad=True)\n",
      "23\n",
      "tensor(-1., requires_grad=True)\n",
      "24\n",
      "tensor(0., requires_grad=True)\n",
      "25\n",
      "tensor(1., requires_grad=True)\n",
      "26\n",
      "tensor(1., requires_grad=True)\n",
      "27\n",
      "tensor(1., requires_grad=True)\n",
      "28\n",
      "tensor(1., requires_grad=True)\n",
      "29\n",
      "tensor(1., requires_grad=True)\n",
      "30\n",
      "tensor(1., requires_grad=True)\n",
      "31\n",
      "tensor(1., requires_grad=True)\n",
      "32\n",
      "tensor(1., requires_grad=True)\n",
      "33\n",
      "tensor(1., requires_grad=True)\n",
      "34\n",
      "tensor(1., requires_grad=True)\n",
      "35\n",
      "tensor(1., requires_grad=True)\n",
      "36\n",
      "tensor(1., requires_grad=True)\n",
      "37\n",
      "tensor(1., requires_grad=True)\n",
      "38\n",
      "tensor(1., requires_grad=True)\n",
      "39\n",
      "tensor(1., requires_grad=True)\n",
      "40\n",
      "tensor(1., requires_grad=True)\n",
      "41\n",
      "tensor(1., requires_grad=True)\n",
      "42\n",
      "tensor(1., requires_grad=True)\n",
      "43\n",
      "tensor(1., requires_grad=True)\n",
      "44\n",
      "tensor(1., requires_grad=True)\n",
      "45\n",
      "tensor(1., requires_grad=True)\n",
      "46\n",
      "tensor(1., requires_grad=True)\n",
      "47\n",
      "tensor(1., requires_grad=True)\n",
      "48\n",
      "tensor(1., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# here I update the fully connected weights so that \n",
    "# for the first 24 pixels the weight is always 1 (of the last featuremap), no matter which output dim\n",
    "# for the last 24 pixels the weight is always -1 (of the last featuremap), no matter which output dim\n",
    "# for the middle pixel the weight is 0\n",
    "# e.g. if the last featuremap is a constant, the contribution to the output of the first fc layer is always 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    par = list(my_vgg.classifier[0].parameters())\n",
    "    par[0].shape # lineair transform part\n",
    "    par[1].shape # bias part\n",
    "    \n",
    "    #par[0].requires_grad_(False)\n",
    "    \n",
    "    temp = torch.Tensor(par[0])\n",
    "    temp.shape\n",
    "    # 49 / 2 = 24.5\n",
    "    temp[:,25088-7*7:25088-7*7+24] = -1\n",
    "    koe = temp[:,25088-7*7:25088-7*7+24]\n",
    "    print(koe.shape)\n",
    "    \n",
    "    temp[:,25088-7*7+25:] = 1\n",
    "    koe2 = temp[:,25088-7*7+25:]\n",
    "    print(koe2.shape)\n",
    "    #temp[:,25088-7*7:] = -1\n",
    "    \n",
    "    koe3 = temp[:,25088-7*7:]\n",
    "    temp[:,25088-7*7+24:25088-7*7+25] = 0\n",
    "    for i in range(0, koe3.shape[1]):\n",
    "        print(i)\n",
    "        print(koe3[1,i])\n",
    "        \n",
    "    par[0].copy_(temp)\n",
    "    \n",
    "    temp_new = par[0]\n",
    "    temp_new[:,25088-7*7:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    my_conv = list(my_vgg.features[34].parameters())\n",
    "    print(my_conv[0].shape) # out channels, in channels, width height\n",
    "    print(my_conv[1].shape) # out channels (bias)\n",
    "    \n",
    "    my_filters = my_conv[0]\n",
    "    my_filters[511,:,:,:] = 0 \n",
    "    \n",
    "    my_conv[0].copy_(my_filters)\n",
    "    \n",
    "    my_bias = my_conv[1]\n",
    "    my_bias[511] = 1\n",
    "    my_conv[1].copy_(my_bias)\n",
    "    \n",
    "    print(' ')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = 'examples/both.png'\n",
    "\n",
    "img = cv2.imread(image_path, 1)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "input = preprocess_image(img)\n",
    "\n",
    "out = my_vgg.features(input)\n",
    "out.shape\n",
    "\n",
    "# because we have changed the filter, the last featuremap is now always constant 1\n",
    "out[0,511,:,:]\n",
    "\n",
    "print(out.shape)\n",
    "out.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 7, 7])\n",
      "torch.Size([1, 25088])\n",
      "koe\n",
      "torch.Size([1, 4096])\n"
     ]
    }
   ],
   "source": [
    "out_new = torch.zeros([1, 512, 7, 7], dtype=torch.float32)\n",
    "print(out_new.shape)\n",
    "\n",
    "out_new.requires_grad_(True)\n",
    "out_reshaped = out_new.view(out.size(0), -1)\n",
    "\n",
    "print(out_reshaped.shape)\n",
    "print('koe')\n",
    "\n",
    "lin1 = my_vgg.classifier[0]\n",
    "\n",
    "out2 = lin1(out_reshaped)\n",
    "out2.shape\n",
    "\n",
    "temp = torch.zeros((1,4096))\n",
    "\n",
    "#temp = torch.tensor((), dtype=torch.float64)\n",
    "#temp = temp.new_zeros([1,4096])\n",
    "temp[0] = 1\n",
    "print(temp.shape)\n",
    "\n",
    "#out2\n",
    "out2.backward(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2541, -2.2751, -1.6149, -1.4170, -1.7010, -1.8688, -0.3981],\n",
       "        [-0.9537, -1.9013, -1.7948, -2.5190, -2.2410, -1.8787, -1.4021],\n",
       "        [-1.4897, -2.7069, -2.5036, -2.4881, -2.2670, -1.9620, -1.5914],\n",
       "        [-1.8933, -2.8844, -3.2446, -2.5657, -2.9462, -2.7795, -1.5191],\n",
       "        [-1.8705, -2.5266, -2.6967, -2.6395, -2.8664, -2.5481, -1.9591],\n",
       "        [-1.8961, -2.8430, -2.8746, -2.9298, -2.3603, -2.9336, -2.4472],\n",
       "        [-0.9034, -1.1682, -1.3405, -1.7849, -1.5787, -1.2692, -0.9564]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_new.grad[0,508,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace)\n",
       "    (34): Conv2d(512, 513, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vgg.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([513, 512, 3, 3])\n",
      "torch.Size([513])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    new_convlayer = torch.nn.Conv2d(512, 513, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    my_param = list(new_convlayer.parameters())\n",
    "\n",
    "    kernel = my_param[0] # kernel\n",
    "    bias = my_param[1] # bias\n",
    "    print(kernel.shape)\n",
    "    print(bias.shape)\n",
    "\n",
    "    my_conv = list(my_vgg.features[34].parameters())\n",
    "    print(my_conv[0].shape) # out channels, in channels, width height\n",
    "    print(my_conv[1].shape) # out channels (bias)\n",
    "\n",
    "    vgg_filters = my_conv[0]\n",
    "    vgg_bias = my_conv[1]\n",
    "\n",
    "    kernel[0:512,:,:,:] = vgg_filters\n",
    "    bias[0:512] = vgg_bias\n",
    "\n",
    "    kernel[512:513,:,:,:] = 0\n",
    "    bias[512:513] = 1\n",
    "\n",
    "    my_vgg.features[34] = new_convlayer\n",
    "\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (25088) must match the existing size (25137) at non-singleton dimension 1.  Target sizes: [4096, 25088].  Tensor sizes: [4096, 25137]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-71a5b04769bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m513\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m7\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mnew_A\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_A\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mnew_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (25088) must match the existing size (25137) at non-singleton dimension 1.  Target sizes: [4096, 25088].  Tensor sizes: [4096, 25137]"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    new_lin = torch.nn.Linear(513 * 7 * 7, 4096)\n",
    "\n",
    "    param_lin = list(my_vgg.classifier[0].parameters())\n",
    "    old_A = param_lin[0]\n",
    "    old_b = param_lin[1]\n",
    "\n",
    "    new_param = list(new_lin.parameters())\n",
    "    new_A = new_param[0]\n",
    "    new_b = new_param[1]\n",
    "\n",
    "    num = 513 * 7 * 7\n",
    "\n",
    "    new_A[:,0:512*7*7] = old_A\n",
    "    new_b.copy_(old_b)\n",
    "\n",
    "    new_A[:,num-7*7:num-7*7+24] = -1\n",
    "    #koe = temp[:,num-7*7:num-7*7+24]\n",
    "    #print(koe.shape)\n",
    "\n",
    "    new_A[:,num-7*7+25:] = 1\n",
    "    #koe2 = temp[:,25088-7*7+25:]\n",
    "    #print(koe2.shape)\n",
    "\n",
    "    #koe3 = temp[:,25088-7*7:]\n",
    "    new_A[:,num-7*7+24:num-7*7+25] = 0\n",
    "    \n",
    "    my_vgg.classifier[0] = new_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace)\n",
       "    (34): Conv2d(512, 513, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25137, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    means = [0.485, 0.456, 0.406]\n",
    "    stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "    preprocessed_img = img.copy()[:, :, ::-1]\n",
    "    for i in range(3):\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "    preprocessed_img = \\\n",
    "        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "    preprocessed_img = torch.from_numpy(preprocessed_img)\n",
    "    preprocessed_img.unsqueeze_(0)\n",
    "    input = Variable(preprocessed_img, requires_grad=True)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_vgg(my_vgg):\n",
    "    # add extra featuremap, this is the convlayer\n",
    "    with torch.no_grad():\n",
    "        new_convlayer = torch.nn.Conv2d(512, 513, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "        my_param = list(new_convlayer.parameters())\n",
    "\n",
    "        kernel = my_param[0]  # kernel\n",
    "        bias = my_param[1]  # bias\n",
    "        print(kernel.shape)\n",
    "        print(bias.shape)\n",
    "\n",
    "        my_conv = list(my_vgg.features[34].parameters())\n",
    "        print(my_conv[0].shape)  # out channels, in channels, width height\n",
    "        print(my_conv[1].shape)  # out channels (bias)\n",
    "\n",
    "        vgg_filters = my_conv[0]\n",
    "        vgg_bias = my_conv[1]\n",
    "\n",
    "        kernel[0:512, :, :, :] = vgg_filters\n",
    "        bias[0:512] = vgg_bias\n",
    "\n",
    "        kernel[512:513, :, :, :] = 0\n",
    "        bias[512:513] = 10\n",
    "\n",
    "        my_vgg.features[34] = new_convlayer\n",
    "\n",
    "    # add new lineair layer\n",
    "    with torch.no_grad():\n",
    "        new_lin = torch.nn.Linear(513 * 7 * 7, 4096)\n",
    "\n",
    "        param_lin = list(my_vgg.classifier[0].parameters())\n",
    "        old_A = param_lin[0]\n",
    "        old_b = param_lin[1]\n",
    "\n",
    "        new_param = list(new_lin.parameters())\n",
    "        new_A = new_param[0]\n",
    "        new_b = new_param[1]\n",
    "\n",
    "        print(old_A.shape)\n",
    "        print(new_A.shape)\n",
    "\n",
    "        num = 513 * 7 * 7\n",
    "\n",
    "        new_A[:, :] = 10\n",
    "        new_A[:, 0: 512 * 7 * 7] = old_A\n",
    "\n",
    "        # 7x7 komen er binnen met een waarde van 1000, en worden daarna nog eens met 1000 vermenigvuldigt\n",
    "\n",
    "        #new_b[:] = old_b[:] - 7*7*1000*1000\n",
    "        new_b.copy_(old_b - 7*7*10*10)\n",
    "\n",
    "        # new_A[:, num - 7 * 7:num - 7 * 7 + 24] = -1\n",
    "        # koe = temp[:,num-7*7:num-7*7+24]\n",
    "        # print(koe.shape)\n",
    "\n",
    "        # new_A[:, num - 7 * 7 + 25:] = 1\n",
    "        # koe2 = temp[:,25088-7*7+25:]\n",
    "        # print(koe2.shape)\n",
    "\n",
    "        # koe3 = temp[:,25088-7*7:]\n",
    "        # new_A[:, num - 7 * 7 + 24:num - 7 * 7 + 25] = 0\n",
    "\n",
    "        print(new_A[0, 512 * 7 * 7:])\n",
    "\n",
    "        my_vgg.classifier[0] = new_lin\n",
    "\n",
    "img = cv2.imread(image_path, 1)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "input = preprocess_image(img)\n",
    "\n",
    "out = my_vgg(input)\n",
    "#out.shape\n",
    "\n",
    "#out[0,512,:,:]\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'both.png'\n",
    "\n",
    "#my_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([513, 512, 3, 3])\n",
      "torch.Size([513])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([4096, 25088])\n",
      "torch.Size([4096, 25137])\n",
      "tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
      "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
      "        10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.,\n",
      "        10., 10., 10., 10., 10., 10., 10.], requires_grad=True)\n",
      "torch.Size([1, 512, 7, 7])\n",
      "torch.Size([1, 512, 7, 7])\n",
      "tensor(0.8669, grad_fn=<SumBackward0>)\n",
      "tensor([[-1.0538e-04, -2.7180e-05, -7.1287e-05, -1.2827e-04, -4.8637e-05,\n",
      "         -1.1110e-04, -1.5664e-04, -2.9802e-06, -6.9618e-05, -5.4359e-05,\n",
      "         -6.9022e-05, -7.1526e-05, -4.9114e-05, -1.2136e-04, -5.4836e-05,\n",
      "         -5.4240e-05, -1.0204e-04, -3.1471e-05, -2.3365e-05, -4.8876e-05,\n",
      "         -3.1948e-05, -2.6226e-05, -3.0041e-05,  1.3351e-05, -4.1544e-05,\n",
      "         -2.8133e-05, -7.5340e-05, -7.7486e-05, -1.2994e-05, -7.4625e-05,\n",
      "         -1.3804e-04, -6.9141e-05, -1.1456e-04,  1.1325e-05, -1.5736e-05,\n",
      "         -3.0994e-06,  6.4611e-05,  1.9550e-05, -4.7684e-05,  5.2452e-06,\n",
      "         -9.5367e-05, -5.5790e-05, -4.8637e-05, -7.1764e-05, -4.4227e-05,\n",
      "         -2.5034e-06, -3.5822e-05, -6.2466e-05, -1.1617e-04, -9.9778e-05,\n",
      "         -4.8935e-05, -8.7857e-05, -6.5267e-06, -9.2983e-06, -7.7486e-06,\n",
      "         -5.9843e-05, -2.8610e-05, -6.1989e-06, -9.9659e-05, -2.7180e-05,\n",
      "         -6.6638e-05, -6.2943e-05, -7.8201e-05, -1.0753e-04, -4.3750e-05,\n",
      "         -3.5763e-05, -5.4359e-05, -5.3629e-05, -3.4332e-05, -2.4796e-05,\n",
      "         -4.2915e-05, -5.6148e-05, -3.0994e-06, -1.3113e-05, -1.4305e-06,\n",
      "         -2.1458e-06,  3.6597e-05, -7.1526e-07,  3.7193e-05,  1.9595e-05,\n",
      "         -1.8120e-05, -3.2187e-05, -6.8665e-05,  2.0027e-05, -5.3406e-05,\n",
      "         -5.7459e-05, -5.1022e-05,  1.1086e-04,  6.4135e-05,  5.4717e-05,\n",
      "         -4.5061e-05, -4.9114e-05, -2.0027e-05, -1.9073e-05, -4.0293e-05,\n",
      "         -3.7670e-05,  1.6689e-05, -7.0572e-05, -5.1498e-05,  3.8147e-06,\n",
      "         -6.9141e-05, -5.9247e-05,  1.1325e-05, -5.0306e-05, -4.1246e-05,\n",
      "         -5.0902e-05, -7.1526e-05,  1.1683e-05, -8.8215e-06, -4.6372e-05,\n",
      "         -6.7711e-05, -5.0068e-05,  4.8876e-05, -3.0756e-05, -7.3075e-05,\n",
      "         -3.4332e-05, -3.2783e-05,  1.0943e-04,  4.5240e-05,  3.9577e-05,\n",
      "         -6.4373e-06,  3.5763e-06,  1.5974e-05, -3.9987e-05, -7.7963e-05,\n",
      "          7.9453e-05, -2.8610e-05, -2.0981e-05, -5.0545e-05, -1.9073e-05,\n",
      "         -1.2398e-05, -3.6240e-05,  2.0981e-05, -6.8665e-05, -6.1989e-05,\n",
      "         -6.1989e-05, -7.1526e-05, -7.0572e-05, -2.5392e-05, -1.6332e-05,\n",
      "         -3.0279e-05, -8.3447e-05, -7.8201e-05, -4.6730e-05, -2.1219e-05,\n",
      "          4.7684e-06,  2.0504e-05, -1.1396e-04, -7.4387e-05, -9.4891e-05,\n",
      "         -5.9009e-05,  2.8133e-05,  8.4639e-05,  1.8150e-04,  1.8167e-04,\n",
      "          1.5306e-04,  1.2112e-04,  4.3213e-05,  3.5524e-05,  3.8147e-06,\n",
      "          2.9147e-05, -1.0490e-05,  6.0558e-05,  2.5749e-05,  3.1948e-05,\n",
      "          4.8161e-05,  6.3181e-06, -2.1160e-05,  1.9073e-05,  3.3021e-05,\n",
      "          3.4332e-05, -4.1485e-05, -2.3365e-05, -2.1458e-05,  4.5776e-05,\n",
      "          7.9691e-05, -5.0664e-06,  3.9041e-05,  7.3910e-06, -9.0599e-05,\n",
      "         -5.1498e-05,  5.2929e-05,  8.7738e-05,  6.6280e-05,  2.9802e-05,\n",
      "          7.9632e-05,  8.9169e-05,  1.4782e-04,  2.4199e-05,  4.8637e-05,\n",
      "          1.1730e-04,  5.1141e-05,  7.7724e-05,  5.7936e-05,  7.9870e-05,\n",
      "         -3.8147e-06,  5.9605e-06,  3.2902e-05,  1.0920e-04,  4.4703e-05,\n",
      "          9.7752e-05,  1.7214e-04,  8.0109e-05,  1.3375e-04,  1.5259e-04,\n",
      "          1.9491e-05, -9.5367e-06,  7.0572e-05,  7.1526e-05, -2.9564e-05,\n",
      "         -4.1962e-05, -8.3447e-06,  3.0041e-05, -3.1948e-05,  6.8188e-05,\n",
      "          7.9870e-05,  1.3769e-04,  4.9353e-05,  1.7792e-05,  3.1471e-05,\n",
      "         -1.2368e-05, -5.5134e-07,  4.9740e-05,  2.6941e-05,  1.5318e-05,\n",
      "         -8.2970e-05,  1.3399e-04, -2.0504e-05,  9.1434e-05,  1.3518e-04,\n",
      "          4.7028e-05,  4.7445e-05,  1.6451e-05,  8.1301e-05,  1.9550e-05,\n",
      "          3.8147e-06,  5.2452e-06, -7.1526e-06,  1.3113e-04,  1.2791e-04,\n",
      "          7.9632e-05,  8.1301e-05, -5.7220e-06,  1.8120e-05,  1.0753e-04,\n",
      "          7.6294e-06, -5.7220e-05,  4.4823e-05,  1.6451e-05,  3.7313e-05,\n",
      "          7.5102e-05,  7.2002e-05,  8.6427e-05, -1.5259e-05,  8.4877e-05,\n",
      "          2.3842e-07,  7.6294e-05,  1.1253e-04,  7.4804e-05,  9.2924e-05,\n",
      "          9.2268e-05,  8.2493e-05,  1.9073e-06,  4.6730e-05,  3.0518e-05,\n",
      "          7.3433e-05,  1.0103e-04,  3.6716e-05,  4.9710e-05, -1.6689e-06,\n",
      "         -1.4424e-05, -2.0146e-05,  1.1325e-05, -3.7909e-05, -8.6069e-05,\n",
      "         -4.9174e-05,  2.3723e-05, -5.4359e-05, -9.5367e-07, -5.9605e-06,\n",
      "         -2.0504e-05,  1.1063e-04,  1.1683e-04,  7.9334e-05,  6.5804e-05,\n",
      "          8.1062e-06, -1.0610e-04,  8.2254e-05, -4.1604e-05, -3.7968e-05,\n",
      "         -8.5592e-05,  1.7107e-05, -8.5831e-06, -6.7353e-06, -1.3471e-05,\n",
      "         -2.2650e-05,  2.7731e-05, -3.2902e-05,  2.8610e-05,  5.8651e-05,\n",
      "         -7.6652e-05, -5.0068e-05, -1.9312e-05, -6.3837e-05, -2.9504e-05,\n",
      "         -4.2140e-05, -1.6272e-05, -5.7220e-05, -2.0027e-05,  5.7220e-06,\n",
      "         -8.7261e-05, -4.9889e-05, -5.9128e-05, -3.5524e-05,  4.1485e-05,\n",
      "         -5.0306e-05,  2.2411e-05, -8.1062e-05, -7.5817e-05, -1.6212e-05,\n",
      "         -5.8174e-05, -9.8705e-05, -8.4400e-05, -2.6464e-05, -7.7248e-05,\n",
      "         -3.1233e-05, -1.0061e-04, -8.5831e-05, -7.1287e-05, -1.1277e-04,\n",
      "         -1.6332e-05, -8.4877e-05,  8.4162e-05, -3.0279e-05, -2.7895e-05,\n",
      "          1.7643e-05,  3.8147e-06, -5.5552e-05,  3.6001e-05, -4.0293e-05,\n",
      "         -4.1157e-05, -5.7459e-05, -9.2149e-05, -3.6255e-05, -1.3849e-04,\n",
      "         -6.0797e-05, -1.3471e-04, -6.8903e-05,  9.9689e-06,  7.6294e-06,\n",
      "         -3.2902e-05,  1.5259e-05, -5.2929e-05, -3.1710e-05,  4.7386e-05,\n",
      "         -7.4863e-05,  6.3300e-05, -3.7193e-05,  5.5879e-05,  1.1447e-04,\n",
      "         -3.3140e-05,  7.1734e-05,  4.0710e-05, -4.6313e-05,  6.2585e-07,\n",
      "         -1.4782e-05, -2.7657e-05, -1.0729e-05,  9.2745e-05,  6.1989e-05,\n",
      "         -1.8716e-05,  5.0426e-05, -9.0599e-06, -2.0027e-05, -2.7418e-05,\n",
      "          0.0000e+00, -3.5048e-05,  4.7371e-05,  3.9339e-05,  1.0133e-05,\n",
      "          6.7472e-05, -1.9073e-05, -1.6212e-05, -2.3365e-05, -1.4782e-05,\n",
      "         -7.5996e-05, -1.3113e-05, -9.5367e-07, -1.5020e-05, -1.0514e-04,\n",
      "         -6.4373e-05, -1.1551e-04, -4.2915e-05, -1.9073e-05, -1.2946e-04,\n",
      "         -7.0095e-05, -7.6056e-05, -6.4373e-05,  3.1590e-05,  1.0967e-05,\n",
      "          4.4346e-05,  5.8338e-06,  7.4565e-05, -2.2888e-05, -2.5272e-05,\n",
      "         -8.6308e-05,  3.6478e-05, -3.6597e-05, -9.4891e-05,  9.9540e-05,\n",
      "         -1.3748e-04,  3.6716e-05,  2.6703e-05, -2.7537e-05,  5.1200e-05,\n",
      "         -3.9458e-05,  3.7730e-05, -3.4988e-05,  1.4544e-05,  3.3736e-05,\n",
      "          3.7789e-05, -2.3365e-05,  9.1791e-06,  9.5367e-06,  2.1696e-05,\n",
      "         -7.2002e-05,  2.3127e-05, -6.2466e-05, -4.4346e-05,  5.7220e-06,\n",
      "         -1.2696e-05,  7.6652e-05, -2.3842e-06, -6.1512e-05,  1.5640e-04,\n",
      "          2.9564e-05,  2.9802e-07, -3.9339e-05, -3.6359e-05,  6.4373e-05,\n",
      "          3.4809e-05,  5.9605e-05,  9.3699e-05,  3.4750e-05, -2.8610e-06,\n",
      "          2.3365e-05, -1.1891e-05,  3.0816e-05, -8.6904e-05, -5.8651e-05,\n",
      "         -9.7275e-05,  4.9472e-05, -4.4703e-08,  1.1587e-04,  4.4703e-06,\n",
      "          1.3471e-05, -4.2379e-05,  2.5511e-05,  2.6762e-05,  7.8917e-05,\n",
      "         -9.3818e-05,  3.9458e-05, -3.5763e-06, -1.0967e-05,  2.2888e-05,\n",
      "         -5.1618e-05, -2.6703e-05, -8.0168e-05,  2.3961e-05, -5.2094e-05,\n",
      "          6.9797e-05,  2.2799e-06, -8.0496e-05,  2.9266e-05,  2.5868e-05,\n",
      "         -6.1512e-05, -5.4359e-05,  6.3479e-05,  5.3883e-05,  4.7326e-05,\n",
      "          5.5790e-05, -2.8372e-05,  4.1664e-05, -3.5286e-05, -4.8757e-05,\n",
      "          8.2508e-05,  8.9407e-06,  6.6757e-06, -7.2479e-05, -9.9421e-05,\n",
      "         -1.8805e-05, -7.8768e-05, -2.9325e-05,  6.3896e-05, -8.7023e-06,\n",
      "          9.9182e-05,  4.4584e-05, -1.7762e-05, -1.9819e-05,  2.1458e-05,\n",
      "         -6.0081e-05,  7.2479e-05, -6.4373e-05,  1.1921e-06, -1.1802e-05,\n",
      "          3.1829e-05,  1.8358e-05,  1.2732e-04, -1.2159e-05, -4.5002e-05,\n",
      "         -4.1962e-05,  6.0320e-05,  3.4451e-05,  2.7359e-05, -3.0994e-06,\n",
      "          7.9155e-05,  7.5221e-05, -7.8321e-05, -7.3552e-05, -1.1921e-05,\n",
      "          1.8120e-05,  7.7724e-05, -3.2663e-05, -2.1458e-06,  3.0220e-05,\n",
      "         -1.1039e-04,  7.8797e-05,  2.4408e-05,  8.9169e-05,  9.7990e-05,\n",
      "          4.6790e-05,  2.0683e-05,  6.3658e-05,  8.9973e-05,  9.9182e-05,\n",
      "         -3.7670e-05, -5.6624e-05, -5.9009e-05,  1.3590e-05, -2.1935e-05,\n",
      "          1.9550e-05,  2.6733e-05, -1.2398e-05,  2.9802e-05,  4.9353e-05,\n",
      "          1.5688e-04,  4.9591e-05, -8.8692e-05,  3.6240e-05, -3.4034e-05,\n",
      "          3.8177e-05,  8.1599e-05,  8.8215e-06,  9.9182e-05, -4.9591e-05,\n",
      "          2.0385e-05, -1.7881e-06, -4.7684e-05, -3.0637e-05, -5.7697e-05,\n",
      "          1.7524e-05, -8.8334e-05, -8.3327e-05, -4.8876e-06,  3.5763e-05,\n",
      "         -1.0622e-04,  8.1778e-05,  4.6253e-05,  1.3351e-05, -6.8188e-05,\n",
      "          7.3910e-06, -4.9412e-05, -1.9073e-05, -7.0333e-05,  1.7166e-05,\n",
      "         -6.4015e-05, -6.0081e-05, -2.0921e-05,  9.0361e-05, -4.6849e-05,\n",
      "         -1.1611e-04,  1.3918e-05, -4.0978e-05, -9.1910e-05, -1.1921e-06,\n",
      "          7.5102e-05,  3.8803e-05, -4.2677e-05,  7.5340e-05,  1.0943e-04,\n",
      "         -7.3195e-05, -1.8120e-05,  2.6226e-05, -2.4438e-05,  1.6689e-06,\n",
      "         -3.7074e-05, -8.4043e-06, -6.1512e-05,  1.4186e-05, -1.1599e-04,\n",
      "          4.5300e-06,  6.0260e-05,  8.5991e-05, -9.3699e-05, -4.3839e-05,\n",
      "         -1.2994e-05,  4.1723e-05,  1.0705e-04,  9.5844e-05, -1.5855e-05,\n",
      "          1.2407e-04, -5.1260e-05, -2.2888e-05,  4.4346e-05,  1.6212e-05,\n",
      "         -5.9605e-06, -1.2875e-05,  7.7665e-05,  3.7700e-05,  8.8692e-05,\n",
      "         -6.1989e-05, -5.8889e-05,  2.0981e-05,  1.6212e-05,  7.1526e-05,\n",
      "          5.7220e-06,  3.3975e-06,  4.7922e-05, -5.2094e-05,  2.3961e-05,\n",
      "         -1.7226e-05,  9.8228e-05,  4.5538e-05,  1.6093e-06, -8.7261e-05,\n",
      "          3.9339e-05, -2.7180e-05, -6.1989e-06,  7.5340e-05,  5.2452e-05,\n",
      "         -1.0812e-04,  3.2783e-05, -2.6703e-05, -1.0133e-04, -1.4096e-05,\n",
      "         -4.5776e-05,  1.3232e-05,  6.5207e-05,  8.7261e-05, -5.5790e-05,\n",
      "          4.3780e-05,  8.9884e-05, -3.5226e-05, -4.4107e-05, -4.8161e-05,\n",
      "          1.0538e-04, -2.1160e-06,  2.1458e-05,  1.5676e-05,  1.2398e-05,\n",
      "         -6.4611e-05,  3.0994e-06,  9.3818e-05, -6.9141e-06,  2.8312e-05,\n",
      "          1.9908e-05, -2.3842e-05,  4.9829e-05, -1.5378e-05,  2.4855e-05,\n",
      "          3.8743e-06, -5.9605e-05,  4.9591e-05,  5.2452e-06,  1.2398e-05,\n",
      "         -5.9634e-05,  4.2915e-06, -2.0027e-05, -2.2650e-05,  5.6863e-05,\n",
      "          9.7632e-05, -7.6294e-06,  2.0027e-05,  3.8147e-06,  2.6941e-05,\n",
      "          3.4809e-05,  6.8307e-05, -3.7342e-05,  1.3538e-05,  9.1553e-05,\n",
      "         -7.7009e-05,  9.7513e-05,  3.0279e-05, -5.9605e-06, -4.1246e-05,\n",
      "          1.9670e-06,  1.1444e-05,  1.0243e-04, -1.1593e-05, -6.5565e-06,\n",
      "          1.5163e-04, -6.3777e-06,  9.4056e-05, -1.6487e-04, -4.8041e-05,\n",
      "         -5.7936e-05, -4.7684e-07,  7.6771e-05,  1.7643e-05,  2.8849e-05,\n",
      "          9.7156e-06, -2.7716e-06,  2.5749e-05,  2.9564e-05, -5.4061e-05,\n",
      "          7.7724e-05, -2.4408e-05,  8.3447e-06, -6.7592e-05, -6.0797e-05,\n",
      "          7.4148e-05,  2.8610e-06,  1.4067e-05,  7.5102e-06,  1.2636e-05,\n",
      "         -2.7418e-05, -4.6253e-05,  5.9336e-05,  6.3896e-05, -4.2915e-06,\n",
      "         -1.0431e-04,  5.6267e-05, -2.4796e-05, -3.2067e-05, -2.0981e-05,\n",
      "          2.8729e-05,  1.6212e-05, -7.3910e-06, -3.8505e-05,  7.4744e-05,\n",
      "          6.1989e-06,  5.6982e-05,  5.5790e-05,  1.1921e-07,  1.0371e-05,\n",
      "          2.1338e-05, -6.3002e-05,  3.8832e-05, -2.4021e-05, -5.3644e-06,\n",
      "          4.2439e-05,  1.0490e-05, -3.5763e-06,  3.1471e-05,  7.8917e-05,\n",
      "         -7.9155e-05, -5.2929e-05,  3.3855e-05, -7.2718e-06,  1.0133e-05,\n",
      "          1.2398e-04,  7.7724e-05,  5.6505e-05, -2.3305e-05, -4.1127e-05,\n",
      "         -9.5367e-06, -1.5259e-05,  4.6730e-05, -5.5730e-05, -1.2875e-05,\n",
      "         -2.5988e-05,  1.4496e-04,  6.6280e-05, -3.4332e-05,  4.9353e-05,\n",
      "          3.4809e-05,  1.9193e-05,  2.9027e-05,  6.3419e-05,  2.9922e-05,\n",
      "         -1.4782e-05, -4.9829e-05,  6.4850e-05, -2.0027e-05, -3.2187e-06,\n",
      "         -2.5272e-05,  5.7578e-05, -4.0412e-05, -1.7166e-05,  3.6240e-05,\n",
      "         -3.0518e-05,  3.6716e-05, -8.2493e-05,  7.2002e-05, -3.6716e-05,\n",
      "         -6.0558e-05,  4.2915e-06,  8.9407e-05, -1.6332e-05,  7.4863e-05,\n",
      "          8.3804e-05,  2.4021e-05, -9.0361e-05, -1.0961e-04,  3.2902e-05,\n",
      "         -2.7180e-05,  1.4067e-05, -1.1683e-04,  5.4836e-06,  9.1791e-06,\n",
      "          4.1962e-05,  8.2016e-05,  1.4305e-06,  1.9073e-06, -1.4305e-05,\n",
      "         -2.6703e-05,  3.8058e-05,  2.6226e-05,  1.0681e-04, -9.5367e-06,\n",
      "         -3.7670e-05, -5.5075e-05, -1.0729e-04,  5.7518e-05,  3.3855e-05,\n",
      "         -9.2506e-05, -4.7684e-07,  9.8228e-05,  2.8610e-05, -1.1265e-04,\n",
      "          5.5909e-05,  8.4877e-05,  1.0610e-05, -4.0054e-05,  5.2214e-05,\n",
      "         -4.2081e-05, -3.9339e-06, -2.5511e-05,  8.0824e-05, -5.9843e-05,\n",
      "          1.2064e-04,  6.4373e-05,  4.8995e-05, -6.1393e-05,  7.9870e-05,\n",
      "          7.6771e-05,  1.4544e-04,  3.5763e-06,  7.3552e-05,  2.4855e-05,\n",
      "         -1.3053e-05,  5.6982e-05, -8.7261e-05, -6.3777e-05,  4.1723e-05,\n",
      "          3.0875e-05,  8.3447e-06, -1.7643e-05, -4.8459e-05,  2.4319e-05,\n",
      "         -1.5497e-06,  1.3828e-05,  4.8161e-05, -4.9353e-05, -3.0518e-05,\n",
      "          1.2368e-05, -6.6638e-05, -3.9101e-05,  4.7684e-06,  3.0622e-05,\n",
      "          1.0303e-04, -1.8358e-05,  3.6478e-05, -2.8610e-05, -2.1458e-05,\n",
      "          6.2138e-05,  1.3828e-05,  4.9591e-05,  9.5367e-07,  4.9829e-05,\n",
      "          3.1948e-05,  9.2983e-06,  4.3869e-05, -5.1022e-05,  1.0610e-05,\n",
      "          1.1802e-05,  2.7224e-05,  3.6478e-05, -1.3065e-04, -5.9247e-05,\n",
      "          5.7220e-06,  3.9071e-05,  1.1790e-04, -1.0777e-04,  1.6165e-04,\n",
      "         -1.7166e-05,  9.0599e-05,  6.1035e-05,  3.9101e-05, -2.1696e-05,\n",
      "         -9.2268e-05,  2.1100e-05, -5.5552e-05,  9.8705e-05, -5.6028e-05,\n",
      "         -2.0504e-05, -1.0669e-05,  4.1723e-05, -4.7207e-05,  1.8954e-05,\n",
      "          1.5736e-05,  1.4991e-05, -1.0300e-04, -1.4472e-04, -1.0490e-05,\n",
      "          4.0174e-05, -6.1154e-05, -2.0266e-06,  5.7220e-06, -6.7353e-05,\n",
      "         -5.6267e-05,  1.5020e-05, -1.8954e-05,  2.8014e-05, -2.0742e-05,\n",
      "          2.2888e-05,  1.0490e-05, -2.0504e-05,  2.8312e-05,  1.0729e-05,\n",
      "         -3.0279e-05, -7.3314e-06, -5.7042e-05,  5.3763e-05,  4.3988e-05,\n",
      "          1.6212e-05, -1.4156e-06, -5.3048e-06,  1.1444e-05,  4.8876e-06,\n",
      "          7.6830e-05,  6.1274e-05,  1.5688e-04, -3.9876e-05,  5.5194e-05,\n",
      "          1.5199e-05, -3.0994e-05,  2.1577e-05, -1.5497e-06, -2.8044e-05,\n",
      "          5.4240e-06, -2.0474e-05, -4.0531e-05, -3.7909e-05, -3.5763e-06,\n",
      "          9.2387e-06, -2.9773e-05, -2.5272e-05, -3.7581e-05,  3.2902e-05,\n",
      "          5.3644e-05,  4.7088e-05, -5.9605e-08, -9.9838e-06,  5.0068e-06,\n",
      "          6.6131e-05,  4.4227e-05, -3.6001e-05, -2.2173e-05,  5.1796e-05,\n",
      "         -4.5776e-05, -3.7193e-05, -4.0770e-05, -5.9366e-05, -6.7711e-05,\n",
      "         -1.6987e-05, -4.7684e-06,  2.6226e-06,  1.5497e-06, -5.7459e-05,\n",
      "         -7.6294e-06, -3.9935e-05,  2.2411e-05, -8.4877e-05, -4.3154e-05,\n",
      "         -6.9857e-05, -4.8637e-05, -1.4722e-05, -8.2493e-05, -5.3167e-05,\n",
      "         -4.7207e-05,  9.5367e-06,  4.5061e-05, -3.3140e-05, -2.7180e-05,\n",
      "          3.7193e-05, -1.3709e-05, -5.1975e-05, -2.1011e-06,  1.2112e-04]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor(0.0464, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "from torchvision import models\n",
    "from torchvision import utils\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "#del my_vgg\n",
    "my_vgg = models.vgg19(pretrained=True)\n",
    "\n",
    "for mod in my_vgg.features:\n",
    "    mod.eval()\n",
    "for mod in my_vgg.classifier:\n",
    "    mod.eval()\n",
    "    \n",
    "\n",
    "img = cv2.imread(image_path, 1)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "input = preprocess_image(img)\n",
    "output_before = my_vgg.features(input)\n",
    "\n",
    "lin1_bf = my_vgg.classifier[0]\n",
    "lin1_bf_out = lin1_bf(output_before.view(1, -1))\n",
    "\n",
    "output_final = my_vgg(input)\n",
    "\n",
    "update_vgg(my_vgg)\n",
    "\n",
    "for mod in my_vgg.features:\n",
    "    mod.eval()\n",
    "for mod in my_vgg.classifier:\n",
    "    mod.eval()\n",
    "    \n",
    "\n",
    "img = cv2.imread(image_path, 1)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "input_new = preprocess_image(img)\n",
    "\n",
    "output_after = my_vgg.features(input_new)\n",
    "\n",
    "lin1_af = my_vgg.classifier[0]\n",
    "lin1_af_out = lin1_af(output_after.view(1, -1))\n",
    "\n",
    "output_after2 = output_after[:,0:512,:,:]\n",
    "print(output_after2.shape)\n",
    "print(output_before.shape)\n",
    "\n",
    "print(torch.sum(torch.abs(lin1_bf_out-lin1_af_out)))\n",
    "# after linear layer \n",
    "lin1_bf_out-lin1_af_out\n",
    "\n",
    "output_final_after = my_vgg(input_new)\n",
    "\n",
    "print(output_final_after - output_final)\n",
    "\n",
    "print(torch.sum(torch.abs(output_final-output_final_after)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1000., 1000., 1000.,  ..., 1000., 1000., 1000.],\n",
       "        [1000., 1000., 1000.,  ..., 1000., 1000., 1000.],\n",
       "        [1000., 1000., 1000.,  ..., 1000., 1000., 1000.],\n",
       "        ...,\n",
       "        [1000., 1000., 1000.,  ..., 1000., 1000., 1000.],\n",
       "        [1000., 1000., 1000.,  ..., 1000., 1000., 1000.],\n",
       "        [1000., 1000., 1000.,  ..., 1000., 1000., 1000.]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xafter = output_after.view(1, -1)\n",
    "xafter_np = xafter.data.cpu().numpy()[0]\n",
    "\n",
    "xbefore = output_before.view(1, -1)\n",
    "xbefore_np = xbefore.data.cpu().numpy()[0]\n",
    "\n",
    "N = len(xafter_np)\n",
    "\n",
    "np.sum(np.abs(xafter_np[0:N-7*7]-xbefore_np))\n",
    "\n",
    "param_lin = list(my_vgg.classifier[0].parameters())\n",
    "Anew, bnew = param_lin\n",
    "\n",
    "result = torch.mm(Anew,torch.t(xafter))\n",
    "result.shape\n",
    "\n",
    "Anew[:,25088:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0.,       0.,       0.,  ..., 1000000., 1000000., 1000000.],\n",
       "        [      0.,       0.,       0.,  ..., 1000000., 1000000., 1000000.],\n",
       "        [      0.,       0.,       0.,  ..., 1000000., 1000000., 1000000.],\n",
       "        ...,\n",
       "        [     -0.,       0.,       0.,  ..., 1000000., 1000000., 1000000.],\n",
       "        [      0.,       0.,      -0.,  ..., 1000000., 1000000., 1000000.],\n",
       "        [     -0.,       0.,       0.,  ..., 1000000., 1000000., 1000000.]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = Anew*(xafter)\n",
    "res2\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_original = models.vgg19(pretrained=True)\n",
    "\n",
    "param_lin_old = list(vgg_original.classifier[0].parameters())\n",
    "Aold, bold = param_lin_old\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(Aold[:,0:25088] - Anew[:,0:25088]))\n",
    "\n",
    "resold = Aold*(xbefore)\n",
    "torch.sum(torch.abs(resold[:,0:25088] - res2[:,0:25088]))\n",
    "\n",
    "resultold = torch.mm(Aold, torch.t(xbefore))\n",
    "x = (resultold-result)\n",
    "xnp = x.data.cpu().numpy()\n",
    "\n",
    "corrected = result - 1000*1000*7*7\n",
    "resultold.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48999944., grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(bold - bnew))/4096\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4888, -2.1575, -1.1421,  ..., -1.4386, -1.4505,  0.6909]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin1_af_out - lin1_bf_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for mod in my_vgg.features:\n",
    "    mod.eval()\n",
    "for mod in my_vgg.classifier:\n",
    "    mod.eval()\n",
    "    \n",
    "y = my_vgg(input_new)\n",
    "y2 = my_vgg(input_new)\n",
    "\n",
    "y-y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-38-6527471edd34>, line 7)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-6527471edd34>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    (np.unique(num)\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = output_after.view(1, -1)\n",
    "x.shape\n",
    "\n",
    "num = x.data.cpu().numpy()[0]\n",
    "(np.unique(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 25137])\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "koe = output_after.view(1, -1)\n",
    "print(koe[-7*7:].shape)\n",
    "x = koe.data.cpu().numpy()[0]\n",
    "for num in x[-7*7:]:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "het werkt, want de alpha is heel groot als je kijkt naar de weights in the gradcam. alleen het probleem is dat mijn featuremap op 0 stond, en dus alsnog geen bijdrage kon leveren aan de gradcam. daarom heb ik nu de featuremap op 1000 gezet, en de volgende lineaire layer ook op 1000. hierdoor komt er als het goed is een contributie bij elke feature van precies 7*7*1000*1000. dit trek ik er nu dus van af via de bias, om hier weer hiervoor te corrigeren zodat de uiteindelijke output constant blijft. maar het lijkt er op alsof er nu iets mis gaat. hiervoor werkte het al prima ook in de gradcam. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
